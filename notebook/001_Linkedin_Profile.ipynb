{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "\n",
    "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../me/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text: \n",
    "        linkedin += text\n",
    "\n",
    "reader_2 = PdfReader(\"../me/Muhammad Ariff Izzham - resume.pdf\")\n",
    "resume = \"\"\n",
    "for page_2 in reader_2.pages:\n",
    "    text_2 = page_2.extract_text()\n",
    "    if text_2: \n",
    "        resume += text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â  Â \n",
      "Contact\n",
      "maizzham01@gmail.com\n",
      "www.linkedin.com/in/\n",
      "izzham-295566 (LinkedIn)\n",
      "bento.me/izzham (Personal)\n",
      "Top Skills\n",
      "Cvat\n",
      "Docker\n",
      "Angular\n",
      "Certifications\n",
      "Google Data Analytics Specialization\n",
      "Pandas\n",
      "Introduction to IoT\n",
      "Process Data from Dirty to Clean\n",
      "Data Cleaning\n",
      "Muhammad Ariff Izzham\n",
      "Burhanuddin\n",
      "Software Developer | Data Science\n",
      "WP. Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia\n",
      "Summary\n",
      "Tech Tanjak !\n",
      "Im interested in technology and tradition. I hope these two can be\n",
      "combined to advance in the future. I want our country and world to\n",
      "be more developed, but at the same time want to take care of the\n",
      "natural resources in this world. - Hm Still thinking\n",
      "Experience\n",
      "TM Research & Development\n",
      "Software Developer\n",
      "September 2024Â -Â PresentÂ (11 months)\n",
      "Enygma.Ai\n",
      "Software Engineer\n",
      "March 2024Â -Â June 2024Â (4 months)\n",
      "Greater Kuala Lumpur\n",
      "-- Trained new model for Object Detection and labelling about 1000+ images \n",
      "-- Assisted Sr. Software Engineer in developing system  \n",
      "-- Deployed S3, Cloudfront and Lambda Functions in the AWS Console using\n",
      "Terraform\n",
      "Kotak Sakti - Data, Analytics & Digital Intelligence\n",
      "Software Engineer\n",
      "August 2023Â -Â September 2023Â (2 months)\n",
      "-- Developed custom OpenAI functions (LLM) to retrieve and process data.\n",
      "-- Managed data in PostgreSQL databases, including CRUD operations and\n",
      "transformations.\n",
      "-- Built web applications with a strong focus on data visualization using\n",
      "Sigma.js.\n",
      "UiTM Green Centre\n",
      "Â  Page 1 of 2Â  Â \n",
      "Software Engineer\n",
      "September 2021Â -Â February 2022Â (6 months)\n",
      "-- Enhanced user engagement by creating visually appealing dashboards\n",
      "(Power BI)\n",
      "-- Achieved a seamless data flow from MySQL DB to Power BI, optimizing data\n",
      "accessibility (Power BI)\n",
      "-- Successfully deployed and maintained websites on the Heroku cloud\n",
      "platform (Heroku)\n",
      "-- Designed an interactive UI that improved user engagement and user\n",
      "satisfaction (Joomla | WordPress)\n",
      "Education\n",
      "Universiti Teknologi MARA\n",
      "Bachelor's degree,Â Intelligent System EngineeringÂ Â·Â (March 2022Â -Â March\n",
      "2024)\n",
      "Universiti Teknologi MARA\n",
      "Diploma,Â Computer ScienceÂ Â·Â (July 2019Â -Â March 2022)\n",
      "SMK Pandan Indah\n",
      "SPMÂ Â·Â (January 2014Â -Â November 2018)\n",
      "Â  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../me/summary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    summary = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Izzham Burhan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary: \\n{summary}\\n\\n## LinkedIn Profile: \\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user , always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Izzham Burhan. You are answering questions on Izzham Burhan's website, particularly questions related to Izzham Burhan's career, background, skills and experience. Your responsibility is to represent Izzham Burhan for interactions on the website as faithfully as possible. You are given a summary of Izzham Burhan's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary: \\nðŸ§‘ Summary of Izzham Burhan\\nName: Izzham Burhan\\nEmail: ariff.burhanuddin@tmrnd.com.my\\nCompany: Telekom Malaysia (specifically TMR&D â€“ Telekom Malaysia Research & Development)\\nWorkspace Handle: @ariff.burhanuddin\\n\\nðŸ‘¨\\u200dðŸ’» Role & Interests\\nYou are an employee at Telekom Malaysia, likely involved in projects that touch on internal documentation, research initiatives, and process optimization. You have an interest in tracking and summarizing discussions, tasks, and progress within your organization.\\n\\nðŸ“Œ Key Interactions\\nYou've asked for summaries of documents and chats.\\n\\nYouâ€™re interested in synthesizing and managing information from various sources.\\n\\nYou are likely working on or involved with multiple projects that require internal collaboration and documentation oversight.\\n\\nðŸ§  General Patterns\\nYou prefer structured and summarized content.\\n\\nYou value clarity, traceability, and concise updates.\\n\\nYou may be involved in work that relates to R&D, project tracking, or internal process documentation.\\n\\n## LinkedIn Profile: \\n\\xa0 \\xa0\\nContact\\nmaizzham01@gmail.com\\nwww.linkedin.com/in/\\nizzham-295566 (LinkedIn)\\nbento.me/izzham (Personal)\\nTop Skills\\nCvat\\nDocker\\nAngular\\nCertifications\\nGoogle Data Analytics Specialization\\nPandas\\nIntroduction to IoT\\nProcess Data from Dirty to Clean\\nData Cleaning\\nMuhammad Ariff Izzham\\nBurhanuddin\\nSoftware Developer | Data Science\\nWP. Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia\\nSummary\\nTech Tanjak !\\nIm interested in technology and tradition. I hope these two can be\\ncombined to advance in the future. I want our country and world to\\nbe more developed, but at the same time want to take care of the\\nnatural resources in this world. - Hm Still thinking\\nExperience\\nTM Research & Development\\nSoftware Developer\\nSeptember 2024\\xa0-\\xa0Present\\xa0(11 months)\\nEnygma.Ai\\nSoftware Engineer\\nMarch 2024\\xa0-\\xa0June 2024\\xa0(4 months)\\nGreater Kuala Lumpur\\n-- Trained new model for Object Detection and labelling about 1000+ images \\n-- Assisted Sr. Software Engineer in developing system  \\n-- Deployed S3, Cloudfront and Lambda Functions in the AWS Console using\\nTerraform\\nKotak Sakti - Data, Analytics & Digital Intelligence\\nSoftware Engineer\\nAugust 2023\\xa0-\\xa0September 2023\\xa0(2 months)\\n-- Developed custom OpenAI functions (LLM) to retrieve and process data.\\n-- Managed data in PostgreSQL databases, including CRUD operations and\\ntransformations.\\n-- Built web applications with a strong focus on data visualization using\\nSigma.js.\\nUiTM Green Centre\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nSoftware Engineer\\nSeptember 2021\\xa0-\\xa0February 2022\\xa0(6 months)\\n-- Enhanced user engagement by creating visually appealing dashboards\\n(Power BI)\\n-- Achieved a seamless data flow from MySQL DB to Power BI, optimizing data\\naccessibility (Power BI)\\n-- Successfully deployed and maintained websites on the Heroku cloud\\nplatform (Heroku)\\n-- Designed an interactive UI that improved user engagement and user\\nsatisfaction (Joomla | WordPress)\\nEducation\\nUniversiti Teknologi MARA\\nBachelor's degree,\\xa0Intelligent System Engineering\\xa0Â·\\xa0(March 2022\\xa0-\\xa0March\\n2024)\\nUniversiti Teknologi MARA\\nDiploma,\\xa0Computer Science\\xa0Â·\\xa0(July 2019\\xa0-\\xa0March 2022)\\nSMK Pandan Indah\\nSPM\\xa0Â·\\xa0(January 2014\\xa0-\\xa0November 2018)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user , always staying in character as Izzham Burhan.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pydantic model for the evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_accurate: bool\n",
    "    feedback: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n## Resume:\\n{resume}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, I do not hold any patents. My work primarily focuses on software development and data science, and while I engage in innovative projects and research initiatives, I have not yet pursued patenting any of my work. If you have any specific questions regarding my projects or experience, feel free to ask!'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_accurate=True, feedback=\"This is a great response, it's accurate given the context, and it's engaging while still being professional.\")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latins\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_accurate:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is good and concise, but slightly inaccurate. Based on the resume, Izzham worked as an intern from Sept 2021 - Feb 2022, and then again from Aug 2023 - Sept 2023, and March 2024 - June 2024 before becoming a Junior Software Developer in Sept 2024. Therefore, the Agent should state that they have been working for 9 months and have internship experiences of 1 year.\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The agent's response is unacceptable. The response is in gibberish. I do not know the reason for that. The agent should provide a natural response to the question.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
